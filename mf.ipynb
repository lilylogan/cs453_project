{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization Song Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PRED = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1855, 8516)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs = pd.read_csv(\"cleaned_data/csr_df.csv\")\n",
    "df_songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      blame it on waylon _ josh thompson\n",
      "0                                      0\n",
      "1                                      0\n",
      "2                                      0\n",
      "3                                      0\n",
      "4                                      0\n",
      "...                                  ...\n",
      "1850                                   0\n",
      "1851                                   0\n",
      "1852                                   0\n",
      "1853                                   0\n",
      "1854                                   0\n",
      "\n",
      "[1855 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "random_sample = df_songs.sample(axis='columns')\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = df_songs.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i think this doesn't do anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = songs.reshape((songs.shape[0], songs.shape[1])), range(songs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new user:\n",
    "new_user_songs = ['greyhound _ swedish house mafia', 'saturday night _ the herbaliser', 'time to pretend _ mgmt']\n",
    "# Create a new user row (all 0s, then set selected songs to 1)\n",
    "new_user_row = np.zeros(songs.shape[1])\n",
    "for song in new_user_songs:\n",
    "    if song in df_songs.columns:\n",
    "        new_user_row[df_songs.columns.get_loc(song)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_songs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Top Recommendations for New User:\n",
      "['million years _ gareth emery', \"fool's gold _ jill scott\", 'firefly _ breaking benjamin', 'greyhound _ swedish house mafia', 'girlfriend - single version _ bobby brown']\n",
      "2. Top Recommendations for New User:\n",
      "['girlfriend - single version _ bobby brown', 'frikitona _ plan b', \"fool's gold _ jill scott\", 'bigfoot _ w&w', 'detroit vs. everybody _ eminem']\n",
      "3. Top Recommendations for New User:\n",
      "['million years _ gareth emery', 'greyhound _ swedish house mafia', 'girlfriend - single version _ bobby brown', 'bigfoot _ w&w', 'love rain - (coffee shop mix) _ mos def']\n",
      "4. Top Recommendations for New User:\n",
      "['firefly _ breaking benjamin', 'bigfoot _ w&w', 'radical - original mix _ dyro', 'greyhound _ swedish house mafia', 'better in time _ leona lewis']\n",
      "5. Top Recommendations for New User:\n",
      "['bigfoot _ w&w', 'girlfriend - single version _ bobby brown', 'radical - original mix _ dyro', 'better in time _ leona lewis', 'million years _ gareth emery']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # random seed\n",
    "    rand = int(random.random()*100)\n",
    "\n",
    "    # split into test and training data (20, 80)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.24,random_state=42)\n",
    "\n",
    "    # TruncatedSVD is a dimensionality reduction technique (similar to PCA)\n",
    "    svd = TruncatedSVD(n_components=200, n_iter=10, random_state=rand)\n",
    "    svd.fit(x)\n",
    "\n",
    "    # fit the training data\n",
    "    # contains the transformed low-dimensional representation\n",
    "    train_mat = svd.transform(x_train)\n",
    "\n",
    "    # dot multiplication of the training matrix and the svd components\n",
    "    # meaning: reconstructs an approximate version of the original data\n",
    "    approx_matrix = np.dot(train_mat, svd.components_)\n",
    "\n",
    "    # Projecting the new user onto the reduced feature space\n",
    "    new_user_mat = np.dot(new_user_row, svd.components_.T)\n",
    "\n",
    "    # Reconstructing predictions in the original space\n",
    "    new_predictions = np.dot(new_user_mat, svd.components_)\n",
    "\n",
    "    # Sorts indices of predicted ratings in descending order (highest ratings first)\n",
    "    recommendations = np.argsort(-new_predictions)\n",
    "\n",
    "    # Selects the top NUM_PRED recommendations\n",
    "    recommendations = [i for i in recommendations][:NUM_PRED]\n",
    "\n",
    "    # Mapping indices to song titles\n",
    "    recommended_songs = [df_songs.columns[i] for i in recommendations]\n",
    "\n",
    "    print(f\"{i+1}. Top Recommendations for New User:\")\n",
    "    print(recommended_songs)\n",
    "    for song in recommended_songs:\n",
    "        list_of_songs.append(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8516"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorts the song recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set - gets rid of duplicates\n",
    "##### sorts the songs based on their frequency in list of songs st least frequent appears first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['better in time _ leona lewis', 'million years _ gareth emery', 'greyhound _ swedish house mafia', 'girlfriend - single version _ bobby brown', 'bigfoot _ w&w']\n"
     ]
    }
   ],
   "source": [
    "res = sorted(set(list_of_songs), key = lambda ele: list_of_songs.count(ele))\n",
    "print(len(res))\n",
    "res = res[len(res)-5:]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_songs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bigfoot _ w&w', 'girlfriend - single version _ bobby brown', 'greyhound _ swedish house mafia', 'million years _ gareth emery', 'better in time _ leona lewis']\n"
     ]
    }
   ],
   "source": [
    "# res = sorted(set(list_of_songs), key = lambda ele: list_of_songs.count(ele))\n",
    "i = len(res) - 1\n",
    "while (i > len(res) - NUM_PRED - 1):\n",
    "    top_songs.append(res[i])\n",
    "    i = i - 1\n",
    "print(top_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Songs: ['greyhound _ swedish house mafia', 'detroit vs. everybody _ eminem', \"fool's gold _ jill scott\", 'radical - original mix _ dyro', 'girlfriend - single version _ bobby brown']\n"
     ]
    }
   ],
   "source": [
    "def mf_recommender(user_songs, num_pred=5, data_path=\"cleaned_data/csr_df.csv\", num_components=200, num_iter=10):\n",
    "    \"\"\"\n",
    "    Recommends songs using Matrix Factorization (SVD).\n",
    "    \n",
    "    Parameters:\n",
    "        user_songs (list): List of song names liked by the user.\n",
    "        data_path (str): Path to the song interaction dataset.\n",
    "        num_components (int): Number of components for SVD.\n",
    "        num_iter (int): Number of iterations for SVD.\n",
    "\n",
    "    Returns:\n",
    "        list: Top recommended songs.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    df_songs = pd.read_csv(data_path)\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    songs = df_songs.to_numpy()\n",
    "\n",
    "    # Initialize new user row (all 0s)\n",
    "    new_user_row = np.zeros(songs.shape[1])\n",
    "    \n",
    "    # Mark songs the user likes\n",
    "    for song in user_songs:\n",
    "        if song in df_songs.columns:\n",
    "            new_user_row[df_songs.columns.get_loc(song)] = 1\n",
    "\n",
    "    list_of_songs = []\n",
    "\n",
    "    for _ in range(5):  # Run multiple times for better recommendations\n",
    "        rand = int(random.random() * 100)  # Random seed\n",
    "\n",
    "        # Prepare training data\n",
    "        x, y = songs.reshape((songs.shape[0], songs.shape[1])), range(songs.shape[0])\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.24, random_state=42)\n",
    "\n",
    "        # Apply SVD for dimensionality reduction\n",
    "        svd = TruncatedSVD(n_components=num_components, n_iter=num_iter, random_state=rand)\n",
    "        svd.fit(x)\n",
    "\n",
    "        # Transform training data\n",
    "        train_mat = svd.transform(x_train)\n",
    "\n",
    "        # Reconstruct an approximate version of original data\n",
    "        approx_matrix = np.dot(train_mat, svd.components_)\n",
    "\n",
    "        # Project new user onto reduced feature space\n",
    "        new_user_mat = np.dot(new_user_row, svd.components_.T)\n",
    "\n",
    "        # Reconstruct predictions in original space\n",
    "        new_predictions = np.dot(new_user_mat, svd.components_)\n",
    "\n",
    "        # Sort indices of predicted ratings in descending order\n",
    "        recommendations = np.argsort(-new_predictions)[:num_pred]\n",
    "\n",
    "        # Convert indices to song names\n",
    "        recommended_songs = [df_songs.columns[i] for i in recommendations]\n",
    "        list_of_songs.extend(recommended_songs)\n",
    "\n",
    "    # Sort songs by frequency of occurrence in recommendations\n",
    "    sorted_songs = sorted(set(list_of_songs), key=lambda song: list_of_songs.count(song))\n",
    "    \n",
    "    # Select the top num_pred songs (returns a list of recommended track keys)\n",
    "    return sorted_songs[-num_pred:]\n",
    "\n",
    "# Test \n",
    "user_songs = ['greyhound _ swedish house mafia', 'saturday night _ the herbaliser', 'time to pretend _ mgmt']\n",
    "recommended_songs = mf_recommender(user_songs)\n",
    "print(\"Recommended Songs:\", recommended_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_venn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_venn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m venn3\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Exploring how similar the outputs from the three methods are (how many recommended songs overlap)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m recommended_songs_euc \u001b[38;5;241m=\u001b[39m [song[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m song \u001b[38;5;129;01min\u001b[39;00m closest_songs_euc]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib_venn'"
     ]
    }
   ],
   "source": [
    "# from matplotlib_venn import venn3\n",
    "\n",
    "# # Exploring how similar the outputs from the three methods are (how many recommended songs overlap)\n",
    "\n",
    "# recommended_songs_euc = [song[0] for song in closest_songs_euc]\n",
    "\n",
    "# # Create a Venn diagram\n",
    "# venn3([set(top_songs), set(recommended_songs_euc), set(recommended_songs_cos)], set_labels=('SVD', 'Euclidean', 'Cosine'))\n",
    "# plt.show()\n",
    "\n",
    "# print([set(top_songs)])\n",
    "# print([set(recommended_songs_euc)])\n",
    "# print([set(recommended_songs_cos)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
