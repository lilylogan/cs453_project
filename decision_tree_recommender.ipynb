{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class DecisionTreeRecommender: \n",
    "    \"\"\" A recommendation system that uses a tree. The tree's main goal is to classify the song title; \n",
    "    however, with the max depth parameter, the user can control the depth. \n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    max_depth : int\n",
    "        The maximum depth of the tree (check scikit learn docs)\n",
    "    min_samples_leaf : int\n",
    "        The minimum number of samples required to split an internal node (check scikit learn docs)\n",
    "    numeric_preprocessor : StandardScaler\n",
    "        preprocessor for the numerical standardization\n",
    "    categorical_preprocessor : OneHotEncoder\n",
    "        preprocessor for the numerical standardization\n",
    "    trees : array of DecisionTreeRegressor\n",
    "        trees that are used to split on the best feature\n",
    "    titles : array of strings\n",
    "        song titles of the data\n",
    "    features : array of arrays\n",
    "        all other features (other than title names)\n",
    "    numeric_features : array of strings\n",
    "        names of the columns of the numerical features to be scaled\n",
    "    categorical_features : array of strings\n",
    "        names of the columns of the categorical features to be scaled\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=10, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth \n",
    "        self.min_sample_leaf = min_samples_leaf \n",
    "        self.numeric_preprocessor = StandardScaler() \n",
    "        self.categorical_preprocessor = OneHotEncoder(drop='first', sparse_output=False) \n",
    "        self.trees = None \n",
    "        self.titles = None \n",
    "        self.features = None \n",
    "        self.numeric_features = None \n",
    "        self.categorical_features = None\n",
    "\n",
    "    def _preprocess_features(self, X):\n",
    "        \"\"\"\n",
    "        Preprocesses both the numerical and the categorical features of the data\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pd.Dataframe\n",
    "            dataframe of attributes and their values for each row\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        processed_df : pd.DataFrame\n",
    "            processed dataframe of both of the types of attributes\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. process the numerical features\n",
    "        if self.numeric_features:\n",
    "            numeric_scaled = self.numeric_preprocessor.fit_transform(X[self.numeric_features])\n",
    "            numeric_df = pd.DataFrame(numeric_scaled, columns=self.numeric_features)\n",
    "        else:\n",
    "            numeric_df = pd.DataFrame()\n",
    "\n",
    "        # 2. process the categorical features\n",
    "        if self.categorical_features:\n",
    "            categorical_scaled = self.categorical_preprocessor.fit_transform(X[self.categorical_features])\n",
    "            # Note: because this is one-hot encoding, we need to get the new and additional names of these columns\n",
    "            categorical_column_names = self.categorical_preprocessor.get_feature_names_out(self.categorical_features)\n",
    "            categorical_df = pd.DataFrame(categorical_scaled, columns=categorical_column_names)\n",
    "\n",
    "        else:\n",
    "            categorical_df = pd.DataFrame()\n",
    "\n",
    "        # 3. combine the dfs into one to be all of the processed features\n",
    "        processed_df = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "\n",
    "        return processed_df\n",
    "    \n",
    "    def _preprocess_single_sample(self, x):\n",
    "        \"\"\"\n",
    "        Preprocesses a single sample. This includes both numerical and categorical features\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        x : series\n",
    "            attributes of a single song\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        processed_df : pd.series \n",
    "            input song's preprocessed attributes\n",
    "        \"\"\"\n",
    "        # note: x needs to be reshaped bc preprocessors use dataframes\n",
    "\n",
    "        # 1. process the numerical features\n",
    "        if self.numeric_features:\n",
    "            numeric_scaled = self.numeric_preprocessor.transform(x[self.numeric_features].reshape(1, -1))\n",
    "            numeric_df = pd.DataFrame(numeric_scaled, columns=self.numeric_features)\n",
    "        else:\n",
    "            numeric_df = pd.DataFrame()\n",
    "\n",
    "        # 2. process the categorical features\n",
    "        if self.categorical_features:\n",
    "            categorical_scaled = self.categorical_preprocessor.transform(x[self.categorical_features].reshape(1, -1))\n",
    "            categorical_column_names = self.categorical_preprocessor.get_feature_names_out(self.categorical_features)\n",
    "            categorical_df = pd.DataFrame(categorical_scaled, columns=categorical_column_names)\n",
    "        else:\n",
    "            categorical_df = pd.DataFrame()\n",
    "\n",
    "        # combine the dfs into one and then return x (scaled) as a series\n",
    "        processed_df = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "        return processed_df.values[0]\n",
    "    \n",
    "    def fit(self, X, song_titles, numeric_features=None, categorical_features=None):\n",
    "        \"\"\"\n",
    "        Fits the decision tree to the given song data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            DataFrame containing both numeric and categorical features\n",
    "        song_titles : array-like\n",
    "            List of song titles\n",
    "        numeric_features : list\n",
    "            List of numeric feature column names\n",
    "        categorical_features : list\n",
    "            List of categorical feature column names\n",
    "        \"\"\"\n",
    "        self.titles = song_titles\n",
    "        self.features = X\n",
    "        self.numeric_features = numeric_features or []\n",
    "        self.categorical_features = categorical_features or []\n",
    "\n",
    "        # 1. preprocess features\n",
    "        scaled_features = self._preprocess_features(X)\n",
    "\n",
    "        # 2. train trees\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class DecisionTreeRecommender:\n",
    "    def __init__(self, max_depth=10, min_sample_leaf=1):\n",
    "        self.max_depth = max_depth # The maximum depth of the tree (check scikit learn docs)\n",
    "        self.min_sample_leaf = min_sample_leaf # The minimum number of samples required to split an internal node (check scikit learn docs)\n",
    "        self.numeric_preprocessor = StandardScaler() # this is to do the numerical standardization\n",
    "        self.categorical_preprocessor = OneHotEncoder(drop='first', sparse_output=False) # this is for categorical\n",
    "        self.trees = None # holds all the trees\n",
    "        self.titles = None # song title names\n",
    "        self.features = None # all other features (other than title names)\n",
    "        self.numeric_features = None \n",
    "        self.categorical_features = None\n",
    "        self.encoded_feature_names = None\n",
    "\n",
    "    def _preprocess_features(self, X):\n",
    "        \"\"\"Preprocess both numeric and categorical features\"\"\"\n",
    "        # Process numeric features\n",
    "        if self.numeric_features:\n",
    "            numeric_scaled = self.numeric_preprocessor.fit_transform(X[self.numeric_features])\n",
    "            numeric_df = pd.DataFrame(\n",
    "                numeric_scaled, \n",
    "                columns=self.numeric_features\n",
    "            )\n",
    "        else:\n",
    "            numeric_df = pd.DataFrame()\n",
    "            \n",
    "        # Process categorical features\n",
    "        if self.categorical_features:\n",
    "            categorical_encoded = self.categorical_preprocessor.fit_transform(X[self.categorical_features])\n",
    "            # Get feature names after one-hot encoding\n",
    "            categorical_names = self.categorical_preprocessor.get_feature_names_out(self.categorical_features)\n",
    "            categorical_df = pd.DataFrame(\n",
    "                categorical_encoded,\n",
    "                columns=categorical_names\n",
    "            )\n",
    "        else:\n",
    "            categorical_df = pd.DataFrame()\n",
    "            \n",
    "        # Combine processed features\n",
    "        processed_df = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "        # self.encoded_feature_names = processed_df.columns.tolist() # this isn't used lol\n",
    "        \n",
    "        return processed_df.values\n",
    "    \n",
    "    def _preprocess_single_sample(self, x):\n",
    "        \"\"\"Preprocess a single sample using fitted preprocessors\"\"\"\n",
    "        # Handle numeric features\n",
    "        if self.numeric_features:\n",
    "            numeric_scaled = self.numeric_preprocessor.transform(x[self.numeric_features].reshape(1, -1))\n",
    "            numeric_df = pd.DataFrame(\n",
    "                numeric_scaled, \n",
    "                columns=self.numeric_features\n",
    "            )\n",
    "        else:\n",
    "            numeric_df = pd.DataFrame()\n",
    "            \n",
    "        # Handle categorical features\n",
    "        if self.categorical_features:\n",
    "            categorical_encoded = self.categorical_preprocessor.transform(x[self.categorical_features].reshape(1, -1))\n",
    "            categorical_names = self.categorical_preprocessor.get_feature_names_out(self.categorical_features)\n",
    "            categorical_df = pd.DataFrame(\n",
    "                categorical_encoded,\n",
    "                columns=categorical_names\n",
    "            )\n",
    "        else:\n",
    "            categorical_df = pd.DataFrame()\n",
    "            \n",
    "        # Combine processed features\n",
    "        processed_df = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "        return processed_df.values[0]\n",
    "\n",
    "    def fit(self, X, song_titles, numeric_features=None, categorical_features=None):\n",
    "        \"\"\"\n",
    "        Fit the recommender system\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas.DataFrame\n",
    "            DataFrame containing both numeric and categorical features\n",
    "        song_titles : array-like\n",
    "            List of song titles\n",
    "        numeric_features : list\n",
    "            List of numeric feature column names\n",
    "        categorical_features : list\n",
    "            List of categorical feature column names\n",
    "        \"\"\"\n",
    "        self.titles = song_titles\n",
    "        self.features = X\n",
    "        self.numeric_features = numeric_features or []\n",
    "        self.categorical_features = categorical_features or []\n",
    "        \n",
    "        # Preprocess features\n",
    "        scaled_features = self._preprocess_features(X)\n",
    "        \n",
    "        # Train a tree for each processed feature\n",
    "        n_features = scaled_features.shape[1]\n",
    "        self.trees = []\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            tree = DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_sample_leaf\n",
    "            )\n",
    "            tree.fit(scaled_features, scaled_features[:, i])\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_features(self, x):\n",
    "        \"\"\"Predict feature values using the decision trees\"\"\"\n",
    "        # Process numeric features\n",
    "        if self.numeric_features:\n",
    "            numeric_data = x[self.numeric_features].values.reshape(1, -1)\n",
    "            numeric_scaled = self.numeric_preprocessor.transform(numeric_data)\n",
    "            numeric_df = pd.DataFrame(\n",
    "                numeric_scaled, \n",
    "                columns=self.numeric_features\n",
    "            )\n",
    "        else:\n",
    "            numeric_df = pd.DataFrame()\n",
    "            \n",
    "        # Process categorical features\n",
    "        if self.categorical_features:\n",
    "            categorical_data = x[self.categorical_features].to_frame().T\n",
    "            categorical_encoded = self.categorical_preprocessor.transform(categorical_data)\n",
    "            categorical_names = self.categorical_preprocessor.get_feature_names_out(self.categorical_features)\n",
    "            categorical_df = pd.DataFrame(\n",
    "                categorical_encoded,\n",
    "                columns=categorical_names\n",
    "            )\n",
    "        else:\n",
    "            categorical_df = pd.DataFrame()\n",
    "            \n",
    "        # Combine processed features\n",
    "        processed_df = pd.concat([numeric_df, categorical_df], axis=1)\n",
    "        scaled_x = processed_df.values[0]\n",
    "        \n",
    "        predictions = np.zeros_like(scaled_x)\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[i] = tree.predict([scaled_x])[0]\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def recommend(self, song_title, top_k=5):\n",
    "        if song_title not in self.titles:\n",
    "            raise ValueError(f\"Song '{song_title}' not found in the training data\")\n",
    "        \n",
    "        song_idx = list(self.titles).index(song_title)\n",
    "        x = self.features.iloc[song_idx]\n",
    "        \n",
    "        # Get predictions for all songs\n",
    "        predictions = np.zeros((len(self.titles), len(self.trees)))\n",
    "        for i in range(len(self.titles)):\n",
    "            if i == song_idx:\n",
    "                continue\n",
    "            predictions[i] = self.predict_features(self.features.iloc[i])\n",
    "        \n",
    "        # Compute similarities \n",
    "        query_prediction = self.predict_features(x)\n",
    "        similarities = cosine_similarity([query_prediction], predictions)[0]\n",
    "        \n",
    "        # Get top-k similar songs\n",
    "        similar_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        # Return the titles of similar songs with similarity scores\n",
    "        recommendations = [\n",
    "            (self.titles[idx], similarities[idx])\n",
    "            for idx in similar_indices\n",
    "        ]\n",
    "        \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "def sklearn_recommendation_system(data_path, song_title, top_k=5, method='clustering'):\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    from pandas.api.types import is_numeric_dtype\n",
    "    numeric_features = [col for col in df.columns if is_numeric_dtype(df[col])]\n",
    "    categorical_features = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "    \n",
    "    # Create and fit the recommender\n",
    "    recommender = DecisionTreeRecommender(max_depth=6)\n",
    "    recommender.fit(\n",
    "        X=df[numeric_features + categorical_features],\n",
    "        song_titles=df['track_name'].values,\n",
    "        numeric_features=numeric_features,\n",
    "        categorical_features=categorical_features\n",
    "    )\n",
    "    \n",
    "    # Get recommendations for a song\n",
    "    recommendations = recommender.recommend(song_title, top_k=4)\n",
    "    \n",
    "    # Print recommendations\n",
    "    print(f\"\\nRecommendations for '{song_title}':\")\n",
    "    for title, score in recommendations:\n",
    "        print(f\"- {title} (similarity: {score:.3f})\")\n",
    "        \n",
    "    return recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created a subset of the data (100 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'Call You Mine':\n",
      "- Need U (similarity: 0.409)\n",
      "- Let Me Love You (Until You Learn To Love Yourself) (similarity: 0.386)\n",
      "- Anything Could Happen (similarity: 0.349)\n",
      "- Roses (similarity: 0.349)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTreeRecommender at 0x14e580193210>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_recommendation_system(\"subset.csv\", \"Call You Mine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6aoGtdWXBkYQ2O2wnyIz2x</td>\n",
       "      <td>Not Ok</td>\n",
       "      <td>Kygo</td>\n",
       "      <td>73</td>\n",
       "      <td>3GTuto6NDtZegL6idSk183</td>\n",
       "      <td>Not Ok</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>Dance Pop</td>\n",
       "      <td>37i9dQZF1DWZQaaqNMbbXa</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>-8.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.408</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id track_name track_artist  track_popularity  \\\n",
       "8  6aoGtdWXBkYQ2O2wnyIz2x     Not Ok         Kygo                73   \n",
       "\n",
       "           track_album_id track_album_name track_album_release_date  \\\n",
       "8  3GTuto6NDtZegL6idSk183           Not Ok               2019-05-23   \n",
       "\n",
       "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
       "8     Dance Pop  37i9dQZF1DWZQaaqNMbbXa            pop  ...  11     -8.14   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "8     0       0.0372        0.0292          0.000002     0.325    0.408   \n",
       "\n",
       "   tempo  duration_ms  \n",
       "8  105.0       210944  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"subset.csv\")\n",
    "df[df[\"track_name\"] == \"Not Ok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6oJ6le65B3SEqPwMRNXWjY</td>\n",
       "      <td>Higher Love</td>\n",
       "      <td>Kygo</td>\n",
       "      <td>87</td>\n",
       "      <td>4wquJImu8RtyEuDtIAsfcE</td>\n",
       "      <td>Higher Love</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.404</td>\n",
       "      <td>103.952</td>\n",
       "      <td>228267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id   track_name track_artist  track_popularity  \\\n",
       "0  6oJ6le65B3SEqPwMRNXWjY  Higher Love         Kygo                87   \n",
       "\n",
       "           track_album_id track_album_name track_album_release_date  \\\n",
       "0  4wquJImu8RtyEuDtIAsfcE      Higher Love               2019-06-28   \n",
       "\n",
       "  playlist_name             playlist_id playlist_genre  ... key  loudness  \\\n",
       "0     Pop Remix  37i9dQZF1DXcZDD7cfEKhW            pop  ...   8    -7.159   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     1       0.0324        0.0154          0.000006     0.101    0.404   \n",
       "\n",
       "     tempo  duration_ms  \n",
       "0  103.952       228267  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"track_name\"] == \"Higher Love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_recommendation_system(\"cleaned_data/songs_cleaned.csv\", \"One Love\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
